# -*- coding: utf-8 -*-
"""Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X76PbF8pDJSVzrg356meE13bhq5cCyRq

#What will be the value of the next player?
By Yamil Kas-Danouche

#Background

Given a database of approx 1435 different players of Fortnite which is a Videogame, batteroyale which was created in 2017. This videogame has 4 mode of playing: Solo, Duo, Trio, or Squad but due to the extensive ammount of data I will only be using the values of the Solo mode for all these 1435 players. The dataset can be found in this link https://www.kaggle.com/datasets/iyadali/fortnite-players-stats?resource=download 

#Problem statement

Depending on the stats of such players, can the stats of a new player be determined?

#Input/Output
input: different values of data only related to solo game-mode of different players. Output: The predicted value for each player.

#Type of problem
Prediction of future values; Regression

#Features and attributes
The raw Features of Solo score, Solo top1, Solo kd, Solo winRatio, Solo matches, Solo kills, Solo minutesPlayed, and I believe will improve classifier performance.


#Desired evaluation metric
Recall and Prediction are really important here because the purpose of the project is to predict new values using training values
"""

import os

os.environ['KAGGLE_USERNAME']='yamilkasdanouche'   # your kaggle username
os.environ['KAGGLE_KEY']='3edf4af72a4808d814d9d715b9285783' # your kaggle API key

! kaggle datasets download -d iyadali/fortnite-players-stats
! unzip fortnite-players-stats.zip

import numpy as np
import pandas as pd
import seaborn as sns
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn import datasets, linear_model
from sklearn.metrics import mean_squared_error, r2_score
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from warnings import filterwarnings
filterwarnings('ignore')
import logging
logging.getLogger("tensorflow").setLevel(logging.ERROR)
tf.autograph.set_verbosity(0)

dataBase = pd.read_csv('Fortnite_players_stats.csv',usecols = [1,2,3,4,5,6,7])

"""The first column that has the names of the players and the other columns that have values of types of game modes other than solo, will be ignored.

#Inspecting the data/drawing inferences
"""

print(dataBase.keys())

dataBase[:5]

dataBase.describe()

sns.set(font_scale=1.5, rc={'figure.figsize':(20,20)})
axis = dataBase.hist(bins = 20, color = 'purple')

# Solo minutesPlayed vs Solo Score
plt.figure(figsize=(10,4))
sns.boxplot(data=dataBase, x = 'Solo minutesPlayed', y = 'Solo score')

"""As we can see from the graph, as the player has more minutes played, its score increases."""

# Solo minutesPlayed vs Solo top1
plt.figure(figsize=(10,4))
sns.boxplot(data=dataBase, x = 'Solo minutesPlayed', y = 'Solo top1')

"""As we can see from the graph, as the player has more minutes played, the number of times that the player finishes in 1rst place stays in average almost the same but increases for a few players"""

# Solo minutesPlayed vs Solo kd
plt.figure(figsize=(10,4))
sns.boxplot(data=dataBase, x = 'Solo minutesPlayed', y = 'Solo kd')

"""As we can see from the graph, as the player has more minutes played, its solo kd score increases from zero but stays almost the same after, which means that the match making algorithm of Fortnite is very good because as the skills of the player get better the matching system will create matches with people of the level of the player to fight with."""

# Solo minutesPlayed vs Solo winRatio
plt.figure(figsize=(10,4))
sns.boxplot(data=dataBase, x = 'Solo minutesPlayed', y = 'Solo winRatio')

"""As we can see from the graph, as the player has more minutes played, its solo win ratio increases for some players, but in mayority it stays the same."""

# Solo minutesPlayed vs Solo matches
plt.figure(figsize=(10,4))
sns.boxplot(data=dataBase, x = 'Solo minutesPlayed', y = 'Solo matches')

"""As is expected, the player more minutes the player has, the more matches he has played. There are some fluctuation on this due to the fact that there are some players that die really quick and others that normally survive the longest, which means that as time goes the fluctuation of the slope will increase."""

# Solo minutesPlayed vs Solo kills
plt.figure(figsize=(10,4))
sns.boxplot(data=dataBase, x = 'Solo minutesPlayed', y = 'Solo kills')

"""Like for Solo 1rst player, some players will have a lot of kills in little time and some that will barely kill 1 in a 1000 matches( maybe bots) so as time increases, the number of kill fluctuates from 0 kills to almost 80k kills."""

X = dataBase.iloc[:,:6].values #all rows - column 1 to 6 (x)
y = dataBase.iloc[:,6].values # minutes column (y)
print(X[:5])
print(y[:5])

"""#Splitting the Data"""

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(X,
                                                    y,
                                                    test_size =0.2,
                                                    random_state = 10)
print(len(dataBase))
print(len(x_train))
print(len(x_test))

"""#Creating a training and testing set."""

x_test.shape, y_test.shape

model = Sequential(
    [
        Dense(75, activation='relu'),
        Dense(75, activation='relu'),
        Dense(1)
    ])

optimizer = tf.keras.optimizers.RMSprop(0.001)

model.compile(loss='mse',
            optimizer=optimizer,
            metrics=['mae', 'mse'])

history = model.fit(
    x_train, y_train, 
    epochs=1000,
)

model.summary()

hist = pd.DataFrame(history.history)
hist['epoch'] = history.epoch
hist.tail()

predictions = model.predict(x_test)
print("predictions = \n", predictions[5:15])
print("\ncurrents = \n",y_test[5:15])

"""#Checking a sample:
As we can see from the numbers ina column and a row above, the numbers of predictions are very close to each other and predictions like this one happens for a lot of new predicted players. It wouldn't make sense to calculate the accuracy due to the fact that the numbers that are being predicted are very big.
"""

test_predictions = model.predict(x_test[:]).flatten()

plt.scatter(y_test[:], test_predictions)
plt.xlabel('True Values [MPG]')
plt.ylabel('Predictions [MPG]')

plt.plot()

"""#Comparing the predicted value to the True value
This plot reflects a linear plot of the values generated and the values compared, so the more linear the line is, the more precise the algorithm is. The slope is almost straight which means that the predictions are very close to accurate, or accurate.
"""

error = test_predictions - y_test[:]
plt.hist(error, bins = 100)
plt.xlabel("Prediction Error [MPG]")
_ = plt.ylabel("Count")

"""#Finding the difference
By substracting the original value to the predicted value we can plot the counts of how many numbers have big gaps and how many numbers actually dont have any difference. As we can see in the slope, such slope extends like a piramid having its middle and higher point on the zero count, which means that a very big amount of numbers have been correctly predicted.

#Conclusion
I am pleased to say that more than the 80% of the values of the MPG are values lower than $\pm$ 5000, so the difference is not that extensive, taking into account that some values are as high as 30k, 5k is actually good for a prediction. It's a fact that When I tested the neural network at 64 of density, the pyramid of MPG was centered at 5000, but after it was increased to 100, the center became 0. But I believe that increasing the number of neurons higher than 100 will not improve the MPG for much.  

##Implementations
If I had more time I would implement on the dataset so that whenever a player enters his minutes played, the algorithm would predict his other values and classify him as a casual player, hardcore player, or just a beginner(noob) player.
"""